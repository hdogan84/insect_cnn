{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logging' from 'absl' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/context.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreading\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function_pb2\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'logging' from 'absl' (unknown location)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>101506</th>\n",
       "      <th>101507</th>\n",
       "      <th>101508</th>\n",
       "      <th>101509</th>\n",
       "      <th>101510</th>\n",
       "      <th>101511</th>\n",
       "      <th>101512</th>\n",
       "      <th>101513</th>\n",
       "      <th>101514</th>\n",
       "      <th>101515</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-97.965850</td>\n",
       "      <td>-108.864583</td>\n",
       "      <td>-135.088198</td>\n",
       "      <td>-90.735054</td>\n",
       "      <td>-104.371846</td>\n",
       "      <td>-101.609820</td>\n",
       "      <td>-101.101982</td>\n",
       "      <td>-117.574518</td>\n",
       "      <td>-93.177560</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.177860</td>\n",
       "      <td>-75.125107</td>\n",
       "      <td>-87.810786</td>\n",
       "      <td>-83.691143</td>\n",
       "      <td>-73.280454</td>\n",
       "      <td>-77.571656</td>\n",
       "      <td>-81.848083</td>\n",
       "      <td>-46.919724</td>\n",
       "      <td>-30.780355</td>\n",
       "      <td>-28.470640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.600775</td>\n",
       "      <td>-108.036477</td>\n",
       "      <td>-100.214372</td>\n",
       "      <td>-88.474726</td>\n",
       "      <td>-111.721297</td>\n",
       "      <td>-93.101602</td>\n",
       "      <td>-93.495046</td>\n",
       "      <td>-94.518262</td>\n",
       "      <td>-94.833876</td>\n",
       "      <td>...</td>\n",
       "      <td>-77.200147</td>\n",
       "      <td>-78.177736</td>\n",
       "      <td>-72.907017</td>\n",
       "      <td>-79.540603</td>\n",
       "      <td>-78.619135</td>\n",
       "      <td>-85.789029</td>\n",
       "      <td>-81.353689</td>\n",
       "      <td>-105.236777</td>\n",
       "      <td>-79.894221</td>\n",
       "      <td>-109.972097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-96.495018</td>\n",
       "      <td>-96.562688</td>\n",
       "      <td>-116.417617</td>\n",
       "      <td>-95.419188</td>\n",
       "      <td>-112.215822</td>\n",
       "      <td>-89.438283</td>\n",
       "      <td>-97.414458</td>\n",
       "      <td>-98.058500</td>\n",
       "      <td>-88.688080</td>\n",
       "      <td>...</td>\n",
       "      <td>-82.624460</td>\n",
       "      <td>-82.358549</td>\n",
       "      <td>-78.091033</td>\n",
       "      <td>-93.480107</td>\n",
       "      <td>-77.426921</td>\n",
       "      <td>-113.507869</td>\n",
       "      <td>-97.245951</td>\n",
       "      <td>-74.550025</td>\n",
       "      <td>-76.434780</td>\n",
       "      <td>-79.464878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-98.606206</td>\n",
       "      <td>-112.833065</td>\n",
       "      <td>-86.226339</td>\n",
       "      <td>-90.900417</td>\n",
       "      <td>-97.853661</td>\n",
       "      <td>-91.110081</td>\n",
       "      <td>-98.220544</td>\n",
       "      <td>-97.734086</td>\n",
       "      <td>-107.444892</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.907371</td>\n",
       "      <td>-75.909692</td>\n",
       "      <td>-87.104386</td>\n",
       "      <td>-87.210603</td>\n",
       "      <td>-76.453268</td>\n",
       "      <td>-76.379573</td>\n",
       "      <td>-87.735980</td>\n",
       "      <td>-93.861260</td>\n",
       "      <td>-74.671070</td>\n",
       "      <td>-120.194799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.106769</td>\n",
       "      <td>-122.428422</td>\n",
       "      <td>-95.130811</td>\n",
       "      <td>-93.196171</td>\n",
       "      <td>-112.508083</td>\n",
       "      <td>-102.458660</td>\n",
       "      <td>-93.133487</td>\n",
       "      <td>-106.476959</td>\n",
       "      <td>-88.825575</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.619009</td>\n",
       "      <td>-72.002974</td>\n",
       "      <td>-101.188097</td>\n",
       "      <td>-79.267035</td>\n",
       "      <td>-81.332663</td>\n",
       "      <td>-80.713896</td>\n",
       "      <td>-86.603326</td>\n",
       "      <td>-72.778928</td>\n",
       "      <td>-83.377252</td>\n",
       "      <td>-83.006033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1           2           3          4           5       \\\n",
       "0     1.0 -97.965850 -108.864583 -135.088198 -90.735054 -104.371846   \n",
       "1     1.0 -99.600775 -108.036477 -100.214372 -88.474726 -111.721297   \n",
       "2     1.0 -96.495018  -96.562688 -116.417617 -95.419188 -112.215822   \n",
       "3     1.0 -98.606206 -112.833065  -86.226339 -90.900417  -97.853661   \n",
       "4     1.0 -99.106769 -122.428422  -95.130811 -93.196171 -112.508083   \n",
       "\n",
       "       6           7           8           9       ...     101506     101507  \\\n",
       "0 -101.609820 -101.101982 -117.574518  -93.177560  ... -81.177860 -75.125107   \n",
       "1  -93.101602  -93.495046  -94.518262  -94.833876  ... -77.200147 -78.177736   \n",
       "2  -89.438283  -97.414458  -98.058500  -88.688080  ... -82.624460 -82.358549   \n",
       "3  -91.110081  -98.220544  -97.734086 -107.444892  ... -85.907371 -75.909692   \n",
       "4 -102.458660  -93.133487 -106.476959  -88.825575  ... -78.619009 -72.002974   \n",
       "\n",
       "       101508     101509     101510      101511     101512      101513  \\\n",
       "0  -87.810786 -83.691143 -73.280454  -77.571656 -81.848083  -46.919724   \n",
       "1  -72.907017 -79.540603 -78.619135  -85.789029 -81.353689 -105.236777   \n",
       "2  -78.091033 -93.480107 -77.426921 -113.507869 -97.245951  -74.550025   \n",
       "3  -87.104386 -87.210603 -76.453268  -76.379573 -87.735980  -93.861260   \n",
       "4 -101.188097 -79.267035 -81.332663  -80.713896 -86.603326  -72.778928   \n",
       "\n",
       "      101514      101515  \n",
       "0 -30.780355  -28.470640  \n",
       "1 -79.894221 -109.972097  \n",
       "2 -76.434780  -79.464878  \n",
       "3 -74.671070 -120.194799  \n",
       "4 -83.377252  -83.006033  \n",
       "\n",
       "[5 rows x 101516 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('train.csv',header=None,index_col=None)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('train.npy', train)\n",
    "train=np.load('train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 101516)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=train[:,0]\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 101515)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=train[:,1:]\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=x_data.reshape([462,257,395,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train test split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x2, y_data, test_size=0.15, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 257, 395, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape=(257,395,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yy=tf.keras.layers.Conv2D(32,(3,3),2,input_shape=inp_shape)(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([369, 128, 197, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([369, 63, 98, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz=tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='valid', data_format=None)(yy)\n",
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([369, 31, 48, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt=tf.keras.layers.Conv2D(8, (3,3), 2)(zz)\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([369, 15, 23, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk=tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='valid', data_format=None)(tt)\n",
    "kk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([369, 2760])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Flatten()(kk).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), 2,activation='relu',input_shape=inp_shape),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='valid', data_format=None),\n",
    "  tf.keras.layers.Conv2D(8, (3,3), 2,activation='relu'),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='valid', data_format=None),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(1028, activation='relu'),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 392 samples\n",
      "392/392 [==============================] - 19s 48ms/sample - loss: 4.2501 - accuracy: 0.5051\n",
      "70/70 - 2s - loss: 0.6094 - accuracy: 0.7000\n",
      "Train on 392 samples\n",
      "392/392 [==============================] - 18s 45ms/sample - loss: 0.6976 - accuracy: 0.6556\n",
      "70/70 - 2s - loss: 0.6630 - accuracy: 0.7571\n",
      "Train on 392 samples\n",
      "392/392 [==============================] - 18s 46ms/sample - loss: 0.6107 - accuracy: 0.7551\n",
      "70/70 - 2s - loss: 0.6072 - accuracy: 0.8000\n",
      "Train on 392 samples\n",
      "392/392 [==============================] - 18s 46ms/sample - loss: 0.5734 - accuracy: 0.7959\n",
      "70/70 - 2s - loss: 0.5874 - accuracy: 0.8000\n",
      "Train on 392 samples\n",
      "392/392 [==============================] - 18s 45ms/sample - loss: 0.4676 - accuracy: 0.8189\n",
      "70/70 - 2s - loss: 0.6013 - accuracy: 0.8286\n"
     ]
    }
   ],
   "source": [
    "for ii in range(0,5):\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    model.evaluate(x_test,  y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/dgnhk_000/Downloads/ARSU 2017/20170330_Uhu/Waldschnepfe_recog/my_model_epochs6_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 392 samples\n",
      "392/392 [==============================] - 18s 46ms/sample - loss: 0.2861 - accuracy: 0.8776\n",
      "70/70 - 2s - loss: 0.6698 - accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "for ii in range(0,1):\n",
    "    model.fit(x_train, y_train, epochs=1)\n",
    "    model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_predict, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[46,  3],\n",
       "       [12,  9]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(y_test, y_pred) \n",
    "confusion_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/dgnhk_000/Downloads/ARSU 2017/20170330_Uhu/Waldschnepfe_recog/my_model_epochs20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "16e4206bc7edf506082542216f58f8317f4008997df114ac614ebc01107cbe24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
